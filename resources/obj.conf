[filter_token_mapper]
class_name = zensols.nlp.FilterTokenMapper
#remove_stop = True
#remove_punctuation = True
#remove_space = True

[map_filter_token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = list: filter_token_mapper

[doc_parser]
class_name = zensols.nlp.SpacyFeatureDocumentParser
lang = en
model_name = ${lang}_core_web_sm
token_normalizer = instance: map_filter_token_normalizer
# indicate which features to keep after the parsing; if this is not given, all
# features are kept and persisted; default to all
#
# 'norm' is good for debuging, 'dep', 'children' and the rest are needed for
# dep head tree features
token_feature_ids = eval({'import': ['zensols.nlp as nlp']}):
  nlp.FeatureToken.FEATURE_IDS
# remove empty sentences or sentences with only whitespace, which happens with
# two space separated sentences starting with spaCey 3
#remove_empty_sentences = True

# handy for when dollar signs are interpreted (and can't be escaped for
# multiple interpolation) for regular expressions, such as:
# eval({'import': ['re']}): re.compile('^${regular_expression_escape:dollar}')
[regular_expression_escape]
dollar = \u0024
