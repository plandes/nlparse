[filter_token_mapper]
class_name = zensols.nlp.FilterTokenMapper
#remove_stop = True
#remove_punctuation = True
#remove_space = True

# downcases all text
[lower_case_token_mapper]
class_name = zensols.nlp.LambdaTokenMapper
map_lambda = lambda x: (x[0], x[1].lower())

# repalces with the lemmatized version of the text
[lemma_token_mapper]
class_name = zensols.nlp.LemmatizeTokenMapper

# replaces spaces and tabs with underscores
[underscore_token_mapper]
class_name = zensols.nlp.SubstituteTokenMapper
regex = r'[ \t]'
replace_char = _

[map_filter_token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = list: filter_token_mapper

[langres]
class_name = zensols.nlp.LanguageResource
lang = en
model_name = ${lang}_core_web_sm
token_normalizer = instance: map_filter_token_normalizer

[doc_parser]
class_name = zensols.nlp.FeatureDocumentParser
langres = instance: langres
# remove empty sentences or sentences with only whitespace, which happens with
# two space separated sentences starting with spaCey 3
#remove_empty_sentences = True
# indicate which features to keep after the parsing; if this is not given, all
# features are kept and persisted
#
# 'norm' is good for debuging, 'dep', 'children' and the rest are needed for
# dep head tree features
#token_feature_ids = eval: set('norm ent dep tag children i dep_ is_punctuation'.split())
