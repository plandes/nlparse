# config
[filter_token_mapper]
class_name = zensols.nlp.FilterTokenMapper
remove_space = True

[token_normalizer]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = list: filter_token_mapper

# [langres]
# class_name = zensols.nlp.LanguageResource
# token_normalizer = instance: token_normalizer

# [langres_default]
# class_name = zensols.nlp.LanguageResource

[doc_parser_default]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: langres_default
remove_empty_sentences = True

[doc_parser]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: langres
token_normalizer = instance: token_normalizer
remove_empty_sentences = True

[doc_parser_feat_subset]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: langres
token_normalizer = instance: token_normalizer
remove_empty_sentences = True
token_feature_ids = set: norm, lemma_, i, idx, sent_i

[doc_parser_feat_no_exist]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: langres
token_normalizer = instance: token_normalizer
remove_empty_sentences = True
token_feature_ids = set: norm, lemma_, i, idx, sent_i, BOGUS

[doc_parser_no_remove_sents]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: langres
token_normalizer = instance: token_normalizer


# combiner
[split_ent_token_mapper]
class_name = zensols.nlp.SplitEntityTokenMapper

[token_normalizer_split_ents]
class_name = zensols.nlp.MapTokenNormalizer
mapper_class_list = list: filter_token_mapper, split_ent_token_mapper

# [doc_parser_split_ents]
# class_name = zensols.nlp.SpacyFeatureDocumentParser
# #class_name = zensols.nlp.LanguageResource
# token_normalizer = instance: token_normalizer_split_ents

[doc_parser_split_ents]
class_name = zensols.nlp.SpacyFeatureDocumentParser
#langres = instance: doc_parser_split_ents
token_normalizer = instance: token_normalizer_split_ents
remove_empty_sentences = True

[no_embed_token_normalizer]
class_name = zensols.nlp.TokenNormalizer
embed_entities = False

# [no_embed_langres]
# class_name = zensols.nlp.LanguageResource
# token_normalizer = instance: no_embed_token_normalizer

[doc_parser_combiner]
class_name = zensols.nlp.MappingCombinerFeatureDocumentParser
#langres = instance: no_embed_langres
token_normalizer = instance: no_embed_token_normalizer
replica_parsers = instance: list: doc_parser_split_ents
overwrite_features = list: ent_

[doc_parser_combiner_reverse]
class_name = zensols.nlp.MappingCombinerFeatureDocumentParser
#langres = instance: doc_parser_split_ents
replica_parsers = instance: list: doc_parser_split_ents
token_normalizer = instance: token_normalizer_split_ents
overwrite_features = list: ent_

# this doesn't work because one (primary multi-token span) to many (replica
# splits entities) mapping isn't supported
[doc_parser_combiner_reverse_2]
class_name = zensols.nlp.MappingCombinerFeatureDocumentParser
#langres = instance: langres_default
replica_parsers = instance: list: doc_parser_split_ents
overwrite_features = list: ent_
